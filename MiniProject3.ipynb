{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MiniProject3",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astudnicki/BME6938-Data-Mining/blob/master/MiniProject3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lF2uJ8LVSQ23",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Load the MNIST dataset into Keras**"
      ]
    },
    {
      "metadata": {
        "id": "x5qtBxAneTYw",
        "colab_type": "code",
        "outputId": "e8a9b02e-ad2e-4a88-acb5-80e363fc658d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot ad hoc mnist instances\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "# load (downloaded if needed) the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# plot 4 images as gray scale\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAFLCAYAAADiejquAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "CMZUrlUUSJ-2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Baseline Model with Multi-Layer Perceptrons**"
      ]
    },
    {
      "metadata": {
        "id": "3tloU27J5p89",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7cCR5k0coMek",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KIvA12RzrgWN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten 28*28 images to a 784 vector for each image\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DFzlDK3soiU6",
        "colab_type": "code",
        "outputId": "6526f86c-52b5-4c43-9840-c2cece4a4feb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "JC63zPEMSjvg",
        "colab_type": "code",
        "outputId": "6b1b3ba3-6b2e-4be4-80e4-a48d50b41bb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# flatten 28*28 images to a 784 vector for each image\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "# define baseline model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        "\tmodel.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 7s - loss: 0.2811 - acc: 0.9206 - val_loss: 0.1411 - val_acc: 0.9574\n",
            "Epoch 2/10\n",
            " - 6s - loss: 0.1115 - acc: 0.9677 - val_loss: 0.0910 - val_acc: 0.9714\n",
            "Epoch 3/10\n",
            " - 6s - loss: 0.0716 - acc: 0.9798 - val_loss: 0.0784 - val_acc: 0.9771\n",
            "Epoch 4/10\n",
            " - 6s - loss: 0.0503 - acc: 0.9856 - val_loss: 0.0752 - val_acc: 0.9762\n",
            "Epoch 5/10\n",
            " - 6s - loss: 0.0373 - acc: 0.9893 - val_loss: 0.0680 - val_acc: 0.9788\n",
            "Epoch 6/10\n",
            " - 6s - loss: 0.0268 - acc: 0.9928 - val_loss: 0.0613 - val_acc: 0.9809\n",
            "Epoch 7/10\n",
            " - 6s - loss: 0.0208 - acc: 0.9946 - val_loss: 0.0627 - val_acc: 0.9803\n",
            "Epoch 8/10\n",
            " - 6s - loss: 0.0140 - acc: 0.9971 - val_loss: 0.0625 - val_acc: 0.9803\n",
            "Epoch 9/10\n",
            " - 6s - loss: 0.0107 - acc: 0.9977 - val_loss: 0.0576 - val_acc: 0.9818\n",
            "Epoch 10/10\n",
            " - 6s - loss: 0.0083 - acc: 0.9983 - val_loss: 0.0603 - val_acc: 0.9819\n",
            "Baseline Error: 1.81%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jhQRtBSSUxee",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Simple Convolutional Neural Network for MNIST**"
      ]
    },
    {
      "metadata": {
        "id": "f6on7Fb2TW8E",
        "colab_type": "code",
        "outputId": "13b687c9-51b5-40d5-d893-c1fbcdee6f5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('th')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "PKU-WQ5cU7ej",
        "colab_type": "code",
        "outputId": "2c62bce0-321f-4367-fdfc-6b9363c98e25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu'))\n",
        "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 60s - loss: 0.2253 - acc: 0.9356 - val_loss: 0.0774 - val_acc: 0.9759\n",
            "Epoch 2/10\n",
            " - 59s - loss: 0.0709 - acc: 0.9786 - val_loss: 0.0441 - val_acc: 0.9851\n",
            "Epoch 3/10\n",
            " - 59s - loss: 0.0507 - acc: 0.9844 - val_loss: 0.0430 - val_acc: 0.9855\n",
            "Epoch 4/10\n",
            " - 59s - loss: 0.0390 - acc: 0.9881 - val_loss: 0.0407 - val_acc: 0.9869\n",
            "Epoch 5/10\n",
            " - 59s - loss: 0.0321 - acc: 0.9899 - val_loss: 0.0340 - val_acc: 0.9892\n",
            "Epoch 6/10\n",
            " - 59s - loss: 0.0264 - acc: 0.9918 - val_loss: 0.0330 - val_acc: 0.9891\n",
            "Epoch 7/10\n",
            " - 59s - loss: 0.0217 - acc: 0.9928 - val_loss: 0.0349 - val_acc: 0.9884\n",
            "Epoch 8/10\n",
            " - 58s - loss: 0.0189 - acc: 0.9940 - val_loss: 0.0330 - val_acc: 0.9887\n",
            "Epoch 9/10\n",
            " - 58s - loss: 0.0151 - acc: 0.9951 - val_loss: 0.0322 - val_acc: 0.9890\n",
            "Epoch 10/10\n",
            " - 58s - loss: 0.0137 - acc: 0.9959 - val_loss: 0.0328 - val_acc: 0.9895\n",
            "CNN Error: 1.05%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hsGeF-8KYuzE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**CIFAR10 Dataset with Multilayer Perceptron **"
      ]
    },
    {
      "metadata": {
        "id": "q9xkC3ELYuB5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "#load data\n",
        "(X_train,y_train),(X_test,y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BDXu82LKm2ia",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CFXEIpgQnBEc",
        "colab_type": "code",
        "outputId": "15820e62-6494-447e-c472-e199d468b430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "32*32*3\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3072"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "yDFUv2qbZFVl",
        "colab_type": "code",
        "outputId": "078f1570-3595-4071-fdf3-d3533e9a51c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# flatten 28*28 images to a 784 vector for each image\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2] * X_train.shape[3]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "# define baseline model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        "\tmodel.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 31s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 67s - loss: 13.1298 - acc: 0.1486 - val_loss: 13.1391 - val_acc: 0.1608\n",
            "Epoch 2/10\n",
            " - 66s - loss: 13.1180 - acc: 0.1579 - val_loss: 13.0528 - val_acc: 0.1571\n",
            "Epoch 3/10\n",
            " - 66s - loss: 13.0868 - acc: 0.1589 - val_loss: 12.9907 - val_acc: 0.1699\n",
            "Epoch 4/10\n",
            " - 66s - loss: 12.9640 - acc: 0.1618 - val_loss: 12.0569 - val_acc: 0.1713\n",
            "Epoch 5/10\n",
            " - 65s - loss: 4.1416 - acc: 0.2902 - val_loss: 1.7475 - val_acc: 0.3691\n",
            "Epoch 6/10\n",
            " - 66s - loss: 1.6813 - acc: 0.4015 - val_loss: 1.6288 - val_acc: 0.4238\n",
            "Epoch 7/10\n",
            " - 66s - loss: 1.6082 - acc: 0.4311 - val_loss: 1.6063 - val_acc: 0.4229\n",
            "Epoch 8/10\n",
            " - 66s - loss: 1.5643 - acc: 0.4449 - val_loss: 1.5606 - val_acc: 0.4444\n",
            "Epoch 9/10\n",
            " - 66s - loss: 1.5310 - acc: 0.4598 - val_loss: 1.5968 - val_acc: 0.4357\n",
            "Epoch 10/10\n",
            " - 66s - loss: 1.4961 - acc: 0.4715 - val_loss: 1.5044 - val_acc: 0.4653\n",
            "Baseline Error: 53.47%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BiJrc6mtuwyb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**CIFAR Dataset with Simple Convolutional Neural Network** "
      ]
    },
    {
      "metadata": {
        "id": "akP-8hoyuwOs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('th')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x0rKiZR5u6p8",
        "colab_type": "code",
        "outputId": "9c19c2b5-7d91-4b6d-9c1e-b18bbe2cdf38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 3, 32, 32).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 3, 32, 32).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (5, 5), input_shape=(3, 32, 32), activation='relu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu'))\n",
        "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 88s - loss: 1.7383 - acc: 0.3811 - val_loss: 1.4591 - val_acc: 0.4830\n",
            "Epoch 2/10\n",
            " - 87s - loss: 1.4017 - acc: 0.5022 - val_loss: 1.3482 - val_acc: 0.5212\n",
            "Epoch 3/10\n",
            " - 86s - loss: 1.3086 - acc: 0.5386 - val_loss: 1.2595 - val_acc: 0.5639\n",
            "Epoch 4/10\n",
            " - 86s - loss: 1.2311 - acc: 0.5687 - val_loss: 1.1998 - val_acc: 0.5770\n",
            "Epoch 5/10\n",
            " - 86s - loss: 1.1643 - acc: 0.5923 - val_loss: 1.1484 - val_acc: 0.5972\n",
            "Epoch 6/10\n",
            " - 86s - loss: 1.1116 - acc: 0.6148 - val_loss: 1.1433 - val_acc: 0.6003\n",
            "Epoch 7/10\n",
            " - 86s - loss: 1.0675 - acc: 0.6300 - val_loss: 1.1103 - val_acc: 0.6105\n",
            "Epoch 8/10\n",
            " - 89s - loss: 1.0275 - acc: 0.6425 - val_loss: 1.0645 - val_acc: 0.6315\n",
            "Epoch 9/10\n",
            " - 88s - loss: 0.9987 - acc: 0.6509 - val_loss: 1.0425 - val_acc: 0.6400\n",
            "Epoch 10/10\n",
            " - 88s - loss: 0.9686 - acc: 0.6607 - val_loss: 1.0321 - val_acc: 0.6435\n",
            "CNN Error: 35.65%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wsDWrn4kcxd1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**RESNET50 with CIFAR10 dataset **"
      ]
    },
    {
      "metadata": {
        "id": "ZBMb6Xz-avSs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from urllib.request import urlopen,urlretrieve\n",
        "from PIL import Image\n",
        "from tqdm import tqdm_notebook\n",
        "%matplotlib inline\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "#from resnets_utils import *\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "\n",
        "\n",
        "from keras.models import load_model\n",
        "from sklearn.datasets import load_files   \n",
        "from keras.utils import np_utils\n",
        "from glob import glob\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "from keras import optimizers\n",
        "from keras.models import Sequential,Model,load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
        "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uZdud-oxbBpN",
        "colab_type": "code",
        "outputId": "8c8ea933-42c4-439e-85c8-73c222fa956a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 32, 32, 3).astype('float32')\n",
        "\n",
        "#Y_test = y_test\n",
        "#Y_train = y_train\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training examples = 50000\n",
            "number of test examples = 10000\n",
            "X_train shape: (50000, 32, 32, 3)\n",
            "Y_train shape: (50000, 10)\n",
            "X_test shape: (10000, 32, 32, 3)\n",
            "Y_test shape: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EOclVCxJcGK5",
        "colab_type": "code",
        "outputId": "ad38c95b-0366-41d2-c822-72e6ca851d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "img_height = 32\n",
        "img_width = 32 \n",
        "num_classes = 10\n",
        "#If imagenet weights are being loaded, \n",
        "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
        "base_model = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
        "\n",
        "#NOTE -- the imagenet outputs 1000 last layer of softmax... so need to take this off \"include_top = FALSE\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ruSp1KV2anP4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.7)(x)\n",
        "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
        "model = Model(inputs = base_model.input, outputs = predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6a_yo1jcE2wc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import SGD, Adam\n",
        "# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "adam = Adam(lr=0.001)\n",
        "model.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "roprHtIzKC5W",
        "colab_type": "code",
        "outputId": "c53daba6-c5ba-493c-dc3e-e2cd57fafdca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs = 10, batch_size = 64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 3982s 80ms/step - loss: 2.2319 - acc: 0.3128\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 3881s 78ms/step - loss: 2.0358 - acc: 0.3532\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 3935s 79ms/step - loss: 2.2606 - acc: 0.2752\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 3951s 79ms/step - loss: 2.0349 - acc: 0.3231\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 3893s 78ms/step - loss: 1.8338 - acc: 0.3824\n",
            "Epoch 6/10\n",
            "  192/50000 [..............................] - ETA: 1:06:50 - loss: 1.8686 - acc: 0.4323"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}